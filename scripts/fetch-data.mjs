import { createHash } from 'node:crypto';
import { execFile as execFileCallback } from 'node:child_process';
import { promises as fs } from 'node:fs';
import path from 'node:path';
import { fileURLToPath } from 'node:url';
import { promisify } from 'node:util';

const BASE_URL = 'https://www.city.namegata.ibaraki.jp';
const LICENSE = 'CC BY 2.1 JP';
const AGENT = 'namegata-open-data/fetch-data v0.1.0';
const execFile = promisify(execFileCallback);

const DATASET_SOURCES = [
  {
    id: 'aed',
    title: 'AEDè¨­ç½®ç®‡æ‰€ä¸€è¦§',
    titleEn: 'AED Locations',
    description: 'è¡Œæ–¹å¸‚å†…ã®AEDï¼ˆè‡ªå‹•ä½“å¤–å¼é™¤ç´°å‹•å™¨ï¼‰è¨­ç½®å ´æ‰€ã‚’ã¾ã¨ã‚ãŸãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚',
    icon: 'ðŸ«€',
    category: 'é˜²ç½ãƒ»å®‰å…¨',
    categoryEn: 'SAFETY',
    updatedAt: '2020-06-25',
    detailCode: 4,
    csvCode: 16,
  },
  {
    id: 'care',
    title: 'ä»‹è­·ã‚µãƒ¼ãƒ“ã‚¹äº‹æ¥­æ‰€ä¸€è¦§',
    titleEn: 'Care Service Facilities',
    description: 'ä»‹è­·ã‚µãƒ¼ãƒ“ã‚¹äº‹æ¥­æ‰€ã®æ‰€åœ¨åœ°ã‚„åŸºæœ¬æƒ…å ±ã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ¥',
    category: 'ç¦ç¥‰',
    categoryEn: 'WELFARE',
    updatedAt: '2020-06-25',
    detailCode: 5,
    csvCode: 19,
  },
  {
    id: 'medical',
    title: 'åŒ»ç™‚æ©Ÿé–¢ä¸€è¦§',
    titleEn: 'Medical Facilities',
    description: 'ç—…é™¢ãƒ»è¨ºç™‚æ‰€ãªã©åŒ»ç™‚æ©Ÿé–¢ã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'âš•ï¸',
    category: 'åŒ»ç™‚',
    categoryEn: 'MEDICAL',
    updatedAt: '2020-06-25',
    detailCode: 6,
    csvCode: 30,
  },
  {
    id: 'fire-water',
    title: 'æ¶ˆé˜²æ°´åˆ©æ–½è¨­ä¸€è¦§',
    titleEn: 'Fire Water Facilities',
    description: 'æ¶ˆé˜²æ´»å‹•ã«ä½¿ã†æ°´åˆ©æ–½è¨­ã®ä½ç½®ãƒ»ç¨®åˆ¥ã‚’ç¢ºèªã§ãã¾ã™ã€‚',
    icon: 'ðŸš’',
    category: 'é˜²ç½ãƒ»å®‰å…¨',
    categoryEn: 'SAFETY',
    updatedAt: '2020-06-25',
    detailCode: 7,
    csvCode: 21,
  },
  {
    id: 'shelters',
    title: 'æŒ‡å®šç·Šæ€¥é¿é›£å ´æ‰€ä¸€è¦§',
    titleEn: 'Emergency Shelters',
    description: 'ç½å®³æ™‚ã®æŒ‡å®šç·Šæ€¥é¿é›£å ´æ‰€ã‚’ã¾ã¨ã‚ãŸãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚',
    icon: 'ðŸ›Ÿ',
    category: 'é˜²ç½ãƒ»å®‰å…¨',
    categoryEn: 'SAFETY',
    updatedAt: '2020-06-25',
    detailCode: 8,
    csvCode: 24,
  },
  {
    id: 'population',
    title: 'åœ°åŸŸãƒ»å¹´é½¢åˆ¥äººå£',
    titleEn: 'Population by Area and Age',
    description: 'åœ°åŸŸåˆ¥ãƒ»å¹´é½¢åˆ¥ã®äººå£æ§‹æˆã‚’ç¢ºèªã§ãã¾ã™ã€‚',
    icon: 'ðŸ‘¥',
    category: 'äººå£',
    categoryEn: 'POPULATION',
    updatedAt: '2021-03-02',
    detailCode: 9,
    csvCode: 26,
  },
  {
    id: 'childcare',
    title: 'å­è‚²ã¦æ–½è¨­ä¸€è¦§',
    titleEn: 'Childcare Facilities',
    description: 'ä¿è‚²æ‰€ãƒ»å¹¼ç¨šåœ’ãªã©å­è‚²ã¦é–¢é€£æ–½è¨­ã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ§’',
    category: 'å­è‚²ã¦',
    categoryEn: 'CHILDCARE',
    updatedAt: '2020-06-25',
    detailCode: 10,
    csvCode: 28,
  },
  {
    id: 'wifi',
    title: 'å…¬è¡†ç„¡ç·šLANã‚¢ã‚¯ã‚»ã‚¹ãƒã‚¤ãƒ³ãƒˆä¸€è¦§',
    titleEn: 'Public Wi-Fi Access Points',
    description: 'å¸‚å†…ã®å…¬è¡†ç„¡ç·šLANã‚¢ã‚¯ã‚»ã‚¹ãƒã‚¤ãƒ³ãƒˆã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ“¶',
    category: 'ICT',
    categoryEn: 'ICT',
    updatedAt: '2021-02-26',
    detailCode: 12,
    csvCode: 32,
  },
  {
    id: 'tourism',
    title: 'è¦³å…‰æ–½è¨­ä¸€è¦§',
    titleEn: 'Tourism Facilities',
    description: 'è¦³å…‰æ–½è¨­ã®æ‰€åœ¨åœ°ã‚„åŸºæœ¬æƒ…å ±ã‚’ã¾ã¨ã‚ãŸä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ—ºï¸',
    category: 'è¦³å…‰',
    categoryEn: 'TOURISM',
    updatedAt: '2020-06-25',
    detailCode: 13,
    csvCode: 34,
  },
  {
    id: 'toilets',
    title: 'å…¬è¡†ãƒˆã‚¤ãƒ¬ä¸€è¦§',
    titleEn: 'Public Toilets',
    description: 'å¸‚å†…å…¬è¡†ãƒˆã‚¤ãƒ¬ã®è¨­ç½®å ´æ‰€ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸš»',
    category: 'ç”Ÿæ´»',
    categoryEn: 'LIVING',
    updatedAt: '2020-06-25',
    detailCode: 14,
    csvCode: 36,
  },
  {
    id: 'public-facilities',
    title: 'å…¬å…±æ–½è¨­ä¸€è¦§',
    titleEn: 'Public Facilities',
    description: 'å¸‚ãŒç®¡ç†ã™ã‚‹ä¸»ãªå…¬å…±æ–½è¨­ã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ›ï¸',
    category: 'è¡Œæ”¿',
    categoryEn: 'GOVERNMENT',
    updatedAt: '2020-06-25',
    detailCode: 15,
    csvCode: 51,
  },
  {
    id: 'open-data-catalog',
    title: 'ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼ˆãƒ¡ã‚¿ï¼‰',
    titleEn: 'Open Data Catalog',
    description: 'å…¬é–‹ä¸­ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ãƒ¡ã‚¿æƒ…å ±ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ§¾',
    category: 'ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿',
    categoryEn: 'METADATA',
    updatedAt: '2021-03-02',
    detailCode: 16,
    csvCode: 53,
  },
  {
    id: 'cultural-properties',
    title: 'æ–‡åŒ–è²¡ä¸€è¦§',
    titleEn: 'Cultural Properties',
    description: 'å¸‚å†…ã®æ–‡åŒ–è²¡æƒ…å ±ï¼ˆç¨®åˆ¥ãƒ»æ‰€åœ¨åœ°ãªã©ï¼‰ã®ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸº',
    category: 'æ–‡åŒ–',
    categoryEn: 'CULTURE',
    updatedAt: '2020-06-25',
    detailCode: 17,
    csvCode: 42,
  },
  {
    id: 'shops',
    title: 'ãŠåº—ä¸€è¦§',
    titleEn: 'Local Shops',
    description: 'è¡Œæ–¹å¸‚å†…ã®åº—èˆ—æƒ…å ±ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸª',
    category: 'å•†æ¥­',
    categoryEn: 'COMMERCE',
    updatedAt: '2020-07-03',
    detailCode: 18,
    csvCode: 55,
  },
  {
    id: 'schools',
    title: 'è¡Œæ–¹å¸‚ç«‹å¹¼ç¨šåœ’ãƒ»å°ä¸­å­¦æ ¡ï¼ˆåœ’å…ãƒ»å…ç«¥ç”Ÿå¾’æ•°ï¼‰ä¸€è¦§',
    titleEn: 'Schools and Student Count',
    description: 'è¡Œæ–¹å¸‚ç«‹å¹¼ç¨šåœ’ãƒ»å°ä¸­å­¦æ ¡ã®åœ’å…ãƒ»å…ç«¥ç”Ÿå¾’æ•°ä¸€è¦§ã§ã™ã€‚',
    icon: 'ðŸ«',
    category: 'æ•™è‚²',
    categoryEn: 'EDUCATION',
    updatedAt: '2023-05-18',
    detailCode: 21,
    csvCode: 60,
  },
];

const rootDir = path.resolve(path.dirname(fileURLToPath(import.meta.url)), '..');
const rawDir = path.join(rootDir, 'public', 'data', 'raw');
const processedDir = path.join(rootDir, 'src', 'data', 'processed');
const evidenceDir = path.join(rootDir, 'src', 'data', 'evidence');
const datasetsFile = path.join(rootDir, 'src', 'data', 'datasets.json');
const evidenceIndexFile = path.join(evidenceDir, 'index.json');

async function ensureDirectories() {
  await Promise.all([
    fs.mkdir(rawDir, { recursive: true }),
    fs.mkdir(processedDir, { recursive: true }),
    fs.mkdir(evidenceDir, { recursive: true }),
  ]);
}

async function clearDirectoryFiles(directoryPath) {
  const entries = await fs.readdir(directoryPath, { withFileTypes: true });
  await Promise.all(
    entries
      .filter(entry => entry.isFile())
      .map(entry => fs.unlink(path.join(directoryPath, entry.name))),
  );
}

async function writeJson(filePath, payload) {
  await fs.writeFile(filePath, `${JSON.stringify(payload, null, 2)}\n`, 'utf8');
}

function parseContentDisposition(value) {
  if (!value) {
    return null;
  }

  const utf8Match = value.match(/filename\*=UTF-8''([^;]+)/i);
  if (utf8Match) {
    return decodeURIComponent(utf8Match[1]);
  }

  const basicMatch = value.match(/filename="?([^";]+)"?/i);
  return basicMatch ? basicMatch[1] : null;
}

function decodeCsv(bytes) {
  const candidates = [
    { encoding: 'shift_jis', fatal: true },
    { encoding: 'utf-8', fatal: true },
    { encoding: 'utf-8', fatal: false },
  ];

  for (const candidate of candidates) {
    try {
      const decoder = new TextDecoder(candidate.encoding, { fatal: candidate.fatal });
      return { text: decoder.decode(bytes), encoding: candidate.encoding };
    } catch {
      // try next encoding
    }
  }

  return { text: bytes.toString('utf8'), encoding: 'utf-8' };
}

function parseCsvRows(text) {
  const rows = [];
  let row = [];
  let value = '';
  let inQuotes = false;

  for (let i = 0; i < text.length; i += 1) {
    const char = text[i];

    if (char === '"') {
      if (inQuotes && text[i + 1] === '"') {
        value += '"';
        i += 1;
      } else {
        inQuotes = !inQuotes;
      }
      continue;
    }

    if (!inQuotes && char === ',') {
      row.push(value);
      value = '';
      continue;
    }

    if (!inQuotes && (char === '\n' || char === '\r')) {
      if (char === '\r' && text[i + 1] === '\n') {
        i += 1;
      }
      row.push(value);
      value = '';
      rows.push(row);
      row = [];
      continue;
    }

    value += char;
  }

  row.push(value);
  rows.push(row);

  while (rows.length > 0 && rows[rows.length - 1].every(cell => cell.trim() === '')) {
    rows.pop();
  }

  if (rows.length > 0 && rows[0].length > 0) {
    rows[0][0] = rows[0][0].replace(/^\uFEFF/, '');
  }

  return rows;
}

function normalizeHeaders(headers) {
  const seen = new Map();

  return headers.map((header, index) => {
    const base = (header?.trim() || `column_${index + 1}`).replace(/\s+/g, '_');
    const current = seen.get(base) || 0;
    seen.set(base, current + 1);

    if (current === 0) {
      return base;
    }

    return `${base}_${current + 1}`;
  });
}

function rowsToRecords(headers, rows) {
  const headerKeys = normalizeHeaders(headers);

  return rows.map(values => {
    const record = {};
    headerKeys.forEach((headerKey, index) => {
      record[headerKey] = values[index] ?? '';
    });
    return record;
  });
}

function buildUrls(detailCode, csvCode) {
  return {
    sourcePageUrl: `${BASE_URL}/opendata.php?mode=detail&code=${detailCode}`,
    sourceUrl: `${BASE_URL}/opendata_download.php?code=${csvCode}`,
  };
}

function parseRawHeaders(rawHeaders) {
  const blocks = rawHeaders.trim().split(/\r?\n\r?\n/);
  const finalBlock = blocks.at(-1) || '';
  const map = new Map();

  for (const line of finalBlock.split(/\r?\n/)) {
    const index = line.indexOf(':');
    if (index <= 0) {
      continue;
    }
    const key = line.slice(0, index).trim().toLowerCase();
    const value = line.slice(index + 1).trim();
    map.set(key, value);
  }

  return map;
}

async function fetchBinaryViaNativeFetch(url) {
  const response = await fetch(url, {
    headers: { 'user-agent': AGENT },
    signal: AbortSignal.timeout(30_000),
  });

  if (!response.ok) {
    throw new Error(`HTTP ${response.status}`);
  }

  const headers = new Map();
  response.headers.forEach((value, key) => {
    headers.set(key.toLowerCase(), value);
  });

  return {
    bytes: Buffer.from(await response.arrayBuffer()),
    headers,
    acquisitionMethod: 'HTTP GET (fetch)',
  };
}

async function fetchBinaryViaCurl(url) {
  const bodyResult = await execFile(
    'curl',
    ['-sS', '-L', '--fail', '--max-time', '30', '--user-agent', AGENT, url],
    {
      encoding: 'buffer',
      maxBuffer: 20 * 1024 * 1024,
    },
  );

  let headers = new Map();
  try {
    const headResult = await execFile(
      'curl',
      ['-sS', '-I', '-L', '--max-time', '30', '--user-agent', AGENT, url],
      {
        encoding: 'utf8',
        maxBuffer: 1024 * 1024,
      },
    );
    headers = parseRawHeaders(headResult.stdout);
  } catch {
    // continue without header metadata
  }

  return {
    bytes: Buffer.from(bodyResult.stdout),
    headers,
    acquisitionMethod: 'HTTP GET (curl fallback)',
  };
}

async function fetchBinary(url) {
  try {
    return await fetchBinaryViaNativeFetch(url);
  } catch (nativeError) {
    try {
      return await fetchBinaryViaCurl(url);
    } catch (curlError) {
      const nativeMessage = nativeError instanceof Error ? nativeError.message : String(nativeError);
      const curlMessage = curlError instanceof Error ? curlError.message : String(curlError);
      throw new Error(`native-fetch: ${nativeMessage}; curl-fallback: ${curlMessage}`);
    }
  }
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function fetchDataset(source) {
  const { sourcePageUrl, sourceUrl } = buildUrls(source.detailCode, source.csvCode);
  const acquiredAt = new Date().toISOString();

  const download = await fetchBinary(sourceUrl);
  const { bytes, headers: responseHeaders, acquisitionMethod } = download;
  const sha256 = createHash('sha256').update(bytes).digest('hex');
  const filename = parseContentDisposition(responseHeaders.get('content-disposition'));
  const { text, encoding } = decodeCsv(bytes);

  const rows = parseCsvRows(text);
  const headers = rows[0] || [];
  const bodyRows = rows.slice(1).filter(row => row.some(value => value.trim() !== ''));
  const records = rowsToRecords(headers, bodyRows);

  const rowCount = records.length;
  const columnCount = headers.length;

  await fs.writeFile(path.join(rawDir, `${source.id}.csv`), bytes);

  await writeJson(path.join(processedDir, `${source.id}.json`), {
    datasetId: source.id,
    title: source.title,
    acquiredAt,
    sourceUrl,
    sourcePageUrl,
    encoding,
    headers,
    rowCount,
    columnCount,
    records,
  });

  const evidence = {
    dataset_id: source.id,
    title: source.title,
    source: {
      url: sourceUrl,
      detail_page_url: sourcePageUrl,
      publisher: 'è¡Œæ–¹å¸‚',
      license: LICENSE,
      original_filename: filename,
    },
    acquisition: {
      timestamp: acquiredAt,
      method: acquisitionMethod,
      agent: AGENT,
    },
    integrity: {
      sha256,
      file_size_bytes: bytes.length,
      row_count: rowCount,
      column_count: columnCount,
    },
    transformation: {
      description: 'CSV (Shift_JIS/UTF-8) ã‚’ UTF-8 ã§èª­ã¿è¾¼ã¿ã€JSONã¸å¤‰æ›ã€‚',
      columns_added: [],
      columns_removed: [],
      rows_filtered: 0,
    },
    artifacts: {
      raw_csv_path: `public/data/raw/${source.id}.csv`,
      processed_json_path: `src/data/processed/${source.id}.json`,
    },
  };

  await writeJson(path.join(evidenceDir, `${source.id}.evidence.json`), evidence);

  const datasetSummary = {
    id: source.id,
    title: source.title,
    titleEn: source.titleEn,
    description: source.description,
    icon: source.icon,
    category: source.category,
    categoryEn: source.categoryEn,
    updatedAt: source.updatedAt,
    format: 'CSV',
    url: sourceUrl,
    sourcePageUrl,
    status: 'available',
    rowCount,
    columnCount,
    fileSizeBytes: bytes.length,
    fetchedAt: acquiredAt,
    license: LICENSE,
    sha256,
  };

  return {
    datasetSummary,
    evidence,
  };
}

async function main() {
  await ensureDirectories();
  await Promise.all([
    clearDirectoryFiles(rawDir),
    clearDirectoryFiles(processedDir),
    clearDirectoryFiles(evidenceDir),
  ]);

  const datasetSummaries = [];
  const evidenceItems = [];

  for (const source of DATASET_SOURCES) {
    const label = `${source.id} (code:${source.csvCode})`;

    try {
      const { datasetSummary, evidence } = await fetchDataset(source);
      datasetSummaries.push(datasetSummary);
      evidenceItems.push(evidence);
      console.log(`OK  ${label}`);
    } catch (error) {
      const { sourcePageUrl, sourceUrl } = buildUrls(source.detailCode, source.csvCode);
      const acquiredAt = new Date().toISOString();
      const errorMessage = error instanceof Error ? error.message : String(error);

      const failedSummary = {
        id: source.id,
        title: source.title,
        titleEn: source.titleEn,
        description: source.description,
        icon: source.icon,
        category: source.category,
        categoryEn: source.categoryEn,
        updatedAt: source.updatedAt,
        format: 'CSV',
        url: sourceUrl,
        sourcePageUrl,
        status: 'unavailable',
        fetchedAt: acquiredAt,
        license: LICENSE,
        error: errorMessage,
      };

      const failedEvidence = {
        dataset_id: source.id,
        title: source.title,
        source: {
          url: sourceUrl,
          detail_page_url: sourcePageUrl,
          publisher: 'è¡Œæ–¹å¸‚',
          license: LICENSE,
        },
        acquisition: {
          timestamp: acquiredAt,
          method: 'HTTP GET',
          agent: AGENT,
        },
        error: errorMessage,
      };

      datasetSummaries.push(failedSummary);
      evidenceItems.push(failedEvidence);
      await writeJson(path.join(evidenceDir, `${source.id}.evidence.json`), failedEvidence);
      console.warn(`NG  ${label}: ${errorMessage}`);
    }

    await sleep(300);
  }

  const generatedAt = new Date().toISOString();

  await writeJson(datasetsFile, datasetSummaries);
  await writeJson(evidenceIndexFile, {
    generatedAt,
    agent: AGENT,
    license: LICENSE,
    datasetCount: datasetSummaries.length,
    availableCount: datasetSummaries.filter(dataset => dataset.status === 'available').length,
    unavailableCount: datasetSummaries.filter(dataset => dataset.status !== 'available').length,
    datasets: evidenceItems,
  });

  console.log(`\nGenerated ${datasetSummaries.length} datasets (${datasetSummaries.filter(dataset => dataset.status === 'available').length} available).`);
}

main().catch(error => {
  console.error(error);
  process.exitCode = 1;
});
